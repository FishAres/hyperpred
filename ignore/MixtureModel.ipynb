{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixture model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: using ProgressMeter.update! in module Main conflicts with an existing identifier.\n"
     ]
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "using Tullio, KernelAbstractions\n",
    "using Zygote\n",
    "using Flux\n",
    "using Flux: batch\n",
    "using Flux.Optimise: Optimiser, update!\n",
    "using Flux.Data: DataLoader\n",
    "using Flux.NNlib: relu\n",
    "using ProgressMeter\n",
    "using Parameters\n",
    "using CUDA, KernelAbstractions\n",
    "using JLD2\n",
    "using TensorBoardLogger: TBLogger, tb_append, log_value, log_image\n",
    "using Logging\n",
    "using PyPlot\n",
    "using Distributions\n",
    "\n",
    "CUDA.allowscalar(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Arg"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@with_kw struct Arg\n",
    "    E::Int = 100\n",
    "    batchsize::Int = 100\n",
    "    K::Int64 = 600\n",
    "    M::Int64 = 256\n",
    "    Z::Int64 = 5\n",
    "    η::Float64 = 0.1\n",
    "    ηᵥ::Float64 = 0.1\n",
    "    ηᵣ::Float64 = 0.01\n",
    "    λ::Float64 = 0.0005\n",
    "    σ::Float64 = 0.01\n",
    "    session::String = \"m1\"\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Arg\n",
       "  E: Int64 300\n",
       "  batchsize: Int64 100\n",
       "  K: Int64 600\n",
       "  M: Int64 256\n",
       "  Z: Int64 5\n",
       "  η: Float64 0.1\n",
       "  ηᵥ: Float64 0.01\n",
       "  ηᵣ: Float64 0.01\n",
       "  λ: Float64 0.0005\n",
       "  σ: Float64 0.01\n",
       "  session: String \"mixture-4\"\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arg = Arg(ηᵣ=0.01, ηᵥ=0.01, η=0.1, session=\"mixture-4\", E=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TBLogger:\n",
       "\t- Log level     : Info\n",
       "\t- Current step  : 0\n",
       "\t- Output        : /home/lpjiang97/Research/temporal-predcode/sparse_code/mixture-gmm/mixture-4-test\n",
       "\t- open files    : 1\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_path = \"../sparse_code/mixture-gmm/\"\n",
    "tblogger_train = TBLogger(string(log_path, \"$(arg.session)-train\"), tb_append)\n",
    "tblogger_test = TBLogger(string(log_path, \"$(arg.session)-test\"), tb_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss_fn (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(x, x̂) = sum((x .- x̂) .^ 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gpu (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if has_cuda()\n",
    "    device!(0)\n",
    "    mydev = gpu\n",
    "else \n",
    "    mydev = cpu\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ISTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zygote.@nograd function soft_threshold(x, λ)\n",
    "    λ = fill(λ, size(x)) |> mydev\n",
    "    return relu.(x - λ) - relu.(-1 * x - λ)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zygote.@nograd converged(r, r₀; σ=0.01) = norm(r - r₀) / (norm(r₀) + 1e-12) < 0.01 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zygote.@nograd function ISTA(I, r, U; η=0.01, λ=0.001) \n",
    "    #opt = Descent(η)\n",
    "    stop = false\n",
    "    c = 0\n",
    "    while !stop\n",
    "        r₀  = copy(r)\n",
    "        grad = gradient(() -> loss_fn(I, U * r), Flux.params(r))\n",
    "        r = r - η .* grad[r]\n",
    "        # spasify\n",
    "        r = soft_threshold(r, λ) |> mydev\n",
    "        # check convergence\n",
    "        stop = converged(r, r₀) \n",
    "        c += 1\n",
    "        if c > 100\n",
    "            println(norm(r .- r₀) / (norm(r₀) + 1e-12))\n",
    "        end\n",
    "    end\n",
    "    return r    \n",
    "end "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network\n",
    "mutable struct Net \n",
    "    U\n",
    "    V\n",
    "    Net(img_size, num_neuron, Z) = new(\n",
    "        randn(img_size, num_neuron) * 0.05,\n",
    "        randn(num_neuron, num_neuron, Z) * 0.025\n",
    "    )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "plot_rf (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function plot_rf(rf, out_dim, M)\n",
    "    rf = reshape(rf, :, out_dim)\n",
    "    # normalize\n",
    "    rf = rf ./ maximum(abs.(rf), dims=1)\n",
    "    rf = reshape(rf, M, M, out_dim)\n",
    "    # plotting\n",
    "    n = Int64(ceil(sqrt(size(rf, 3))))\n",
    "    fig, axes = plt.subplots(nrows=n, ncols=n, sharex=true, sharey=true)\n",
    "    fig.set_size_inches(10, 10)\n",
    "    for i in 1:size(rf, 3)\n",
    "        ax = axes[i]\n",
    "        ax.imshow(rf[:,:,i], cmap=\"gray\", vmin=-1, vmax=1)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_aspect(\"equal\")\n",
    "    end\n",
    "    for j in size(rf, 3) + 1 : n * n\n",
    "        ax = axes[j]\n",
    "        ax.imshow(ones_like(rf[:,:,1]) .* -1, cmap=\"gray\", vmin=-1, vmax=1)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_aspect(\"equal\")\n",
    "    end\n",
    "    fig.subplots_adjust(wspace=0.0, hspace=0.0)\n",
    "    return fig \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zygote.@nograd norm_rf(U) = U ./ sqrt.(sum(U.^ 2, dims=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "@load \"../data/training.jld2\" train_data\n",
    "@load \"../data/testing.jld2\" test_data\n",
    "train_loader = DataLoader(train_data, batchsize=arg.batchsize, shuffle=true);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(arg.M, arg.K, arg.Z)\n",
    "net.U = net.U |> mydev\n",
    "net.V = net.V |> mydev;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_mixture (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function fit_mixture(r, rₚ, V) \n",
    "    \n",
    "    @tullio μ[k,b,z] := V[k,f,z] * rₚ[f,b] \n",
    "    μ = relu.(μ)\n",
    "\n",
    "    Σ = fill(0.01, size(μ))\n",
    "    W = zeros(size(rₚ, 2), size(V, 3)) \n",
    "    for z = 1:size(V, 3)\n",
    "        for b = 1:size(rₚ, 2)\n",
    "            @inbounds W[b,z] = logpdf(MvNormal(μ[:,b,z], Σ[:,b,z] |> cpu), r[:, b])\n",
    "        end\n",
    "    end\n",
    "    # normalize\n",
    "    return W ./ sum(W, dims=2)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@save \"testing_struct.jld\" (net.U |> cpu) (net.V |> cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Symbol,1}:\n",
       " Symbol(\"net.U |> cpu\")\n",
       " Symbol(\"net.V |> cpu\")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@load \"testing_struct.jld\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function time_prediction(V, W, r)\n",
    "    Z = size(V, 3)\n",
    "    K = size(V, 1)\n",
    "    batchsize = size(r, 2)\n",
    "    M = reshape(V, (:, Z)) * W';\n",
    "    M = reshape(M, (K, K, :))\n",
    "    r̂ₜ = batched_mul(M, reshape(r, (K, 1, :)))[:, 1, :];\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "epoch_progress = Progress(arg.E, \"Epoch\")\n",
    "opt = Descent(arg.η) |> mydev\n",
    "opt_time = Descent(arg.ηᵥ) |> mydev\n",
    "R = nothing\n",
    "r = nothing\n",
    "r̂ = nothing\n",
    "for e = 1:arg.E\n",
    "    train_loss_img = 0.0\n",
    "    train_loss_time = 0.0\n",
    "    p = Progress(length(train_loader), \"Training\")\n",
    "    c = 1\n",
    "    for I in train_loader\n",
    "        T = size(I, 1)\n",
    "        batchsize = size(I, 4)\n",
    "        K = size(net.U, 2)\n",
    "        I = reshape(I, (T, :, batchsize)) |> mydev\n",
    "        # fit mixture weights\n",
    "        rₚ = ISTA(I[1,:,:], zeros(K, batchsize) |> mydev, net.U, η=arg.ηᵣ, λ=arg.λ)\n",
    "        r = ISTA(I[2,:,:], zeros(K, batchsize) |> mydev, net.U, η=arg.ηᵣ, λ=arg.λ)\n",
    "        W = fit_mixture(r |> cpu, rₚ |> cpu, net.V |> cpu) |> mydev\n",
    "        # take gradient\n",
    "        grad = gradient(Flux.params(net.V, net.U)) do \n",
    "            l = 0.0 \n",
    "            for t = 3:T\n",
    "                r̂ = time_prediction(net.V, W, r)\n",
    "                @show r̂\n",
    "                Zygote.ignore() do \n",
    "                    r = ISTA(I[t, :, :], copy(r̂), net.U, η=arg.η, λ=arg.λ)\n",
    "                end\n",
    "                l += loss_fn(r̂, r)\n",
    "                # image loss\n",
    "                l += loss_fn(I[t, :, :], net.U * r)\n",
    "                break\n",
    "            end\n",
    "            l\n",
    "        end\n",
    "        # update weights\n",
    "        update!(opt, Flux.params(net.U), grad)\n",
    "        update!(opt_time, Flux.params(net.V), grad)\n",
    "        # normalize\n",
    "        net.U = norm_rf(net.U) \n",
    "        if mod(c, 25) == 0\n",
    "            step = (e-1) * length(train_loader) + c\n",
    "            log_value(tblogger_train, \"Time Loss\", train_loss_time / step, step=step)\n",
    "            log_value(tblogger_train, \"Img Loss\", train_loss_img / step, step=step)\n",
    "        end\n",
    "        c += 1\n",
    "        ProgressMeter.next!(p)\n",
    "        break\n",
    "    end\n",
    "    RF = net.U |> cpu\n",
    "    fig = plot_rf(RF[:, 1:100], 100, 16)\n",
    "    log_image(tblogger_train, \"rf\", fig, step=e * length(train_loader))\n",
    "    log_value(tblogger_train, \"Time Loss\", train_loss_time, step=e * length(train_loader))\n",
    "    log_value(tblogger_train, \"Img Loss\", train_loss_img, step=e * length(train_loader))\n",
    "    if mod(e, 2) == 0\n",
    "        RF = net.U |> cpu\n",
    "        fig = plot_rf(RF[:, 1:100], 100, 16)\n",
    "        log_image(tblogger_train, \"rf\", fig, step=e * length(train_loader))\n",
    "        @save \"../RFs/net_$e.jld\" net\n",
    "    end\n",
    "    ProgressMeter.next!(epoch_progress)\n",
    "    break\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.0",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
